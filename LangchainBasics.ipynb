{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPawSOi2eXIH6FQNMjIIrYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bittuuu17/LangChain-Basics/blob/main/LangchainBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLAb8xKJs6M2",
        "outputId": "9507c4eb-0932-4b23-f92c-cad4e09c9f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Install LangChain and Google Gemini integration\n",
        "!pip install -q langchain langchain-google-genai\n",
        "\n",
        "print(\"Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "2kKyouXotwWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Set your API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# Initialize the Gemini model\n",
        "# Using gemini-flash\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-flash-latest\",\n",
        "    temperature=0.7,  # Controls randomness (0=focused, 1=creative)\n",
        "    max_tokens=None,  # No limit on response length\n",
        ")\n",
        "\n",
        "print(\"Gemini API setup complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHRl9EtHvUxx",
        "outputId": "b6c02dde-2826-47d6-a197-4d0d6f9a4c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"What is LangChain in one sentence?\")\n",
        "print(\"Response:\")\n",
        "print(response.content)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzVqSGsyGaQo",
        "outputId": "4bb5411e-8d8d-487b-a3cd-c6c2661eb001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "[{'type': 'text', 'text': 'LangChain is an open-source framework designed to simplify the creation of applications powered by large language models (LLMs) by connecting them to external data sources, memory, and other computational tools.', 'extras': {'signature': 'Eo8LCowLAb4+9vuBh4UH0rz0g99eiMqnE4FRQRRhTDnlMwkwKk9gneEXGECfFcYCxHvDKoxaXe7aJc5m5DahPSX8tmyAKetBGAb+DQVJY/w5TI1zVJGOk4VyYz2o4bwr8+r8nO+MJ3yVQFzfW1RHmbc2tqPa3rcJ3mlpCeRQGO+CrwUdgsQzP7PAUd1JcYnKQY4ZAX3lmUi+nx4DKBk5Vo46vMOt6sOWaczxLcrks5xfdJams+J6QiOpuHM+lpVR4t7TLxPenVoUPoiCltF6GF3knowNtnLT8tXGZQbEOl2Srb9JnluA8gViVtfK5I4ih0/QkzliuBt48JKyjellONtZKKsNfnNwix0qoE1Q7C1skX4XYbKlqGRgCth50p4j1UMlscbEqwavILjghfLQ9kGVD56CDbjwFlgMzCtPPYKR4GObgNkJfQx1gMxB7tOolnay8q/lpsHhlg9DNPe4nVKU7091Sl7I6KMNZ27H18bSGkSyYeAlESSSoGIs2xzzMkWUP+GEdb+9rHm2hSatbzW2GqX2fWivjxULBCzjUlMlUiucYxvmqEEZP1kL3snA9OIcwCZdWxN5CoGO5+SDtuIaXrBzj22J2EaiESNvTLHw16kmLIpyRhO5u/tc5ney+e3bsc7PS7VAcHjpvMG6makjOf1DKUD7j0mVtu+E0B4OXm6C0wubAL5sy0EA6feL88SFe/9RkYXCuTxvitJb3xBO+7Ce2VhIi7VnralzdsWRxGZhrxs1taX4myeMh2f1Nkk4qENITfMTdO0YbXfPccJhmqeVqAf5dr8hgApscZNMGwEUUtaUrahQF/aQ2B79EXvQh6+mKeUO2b53xCPdJDEp00wYEMmk9gz2CWsrjkYJ6bdrPXMOR4Q0H6x9O3ZUiH8FHY2xlaNHdA92TjXTleyQugt6yDcpjaJJ7Eng9+AlqibZjNJ/SkVUjIGOqxjVmXVxOGLGuRCdS1WOYIvdwoqSWsRP6apeU6scIdPl0RomMODfO1sG7PfP8Cgk5aFNzN9c6mpYPxNxh4Vlkw49BYLTAZVCH4SJmYtfh50u5Ko6c10Ls48TeC6ZEm7V36ACB8sBN9b0mMqBj6SGy1yuarr29LtvEhwGamLaUKDeF2JcGPsAphkDv649K/9JZ95qPjTRL3U5FTw/4sRNnzTIunMKA4DWG4UbxNhZ6N769WzkCV94fRzM/C05G7bJJ0EsqsvtscGkc9k6j+3FWoncpuKA3/mnoQN9weyqmNV0Dg83VZPF+1A3blBuQh41GnOBARhsG5wTHQKd1xHE+vO/k/pNXKv7AM9p8l9nGD2lz8FwQy4Mh+7pVtKcAJpdzHtALf80RDOsATeue7QUHMnnVT/MQJ/uKVUCteWng13/TSdiKEsSj80JVCcfTkJMtpfmhz95N/nPU6nXJI8OTk3k0kpG4Te36wOc59xfiqyydEzIjBitwFZFTRciZSxTT1tz5iqVjaewotxpHp9xXU8nTpAKJQy7y9qyFFZRZ2agiZHhORvAmbu2rnfnFHDWwDnCoRCFgZn9UEcHrm3Kf9+h8LFzFxlMpVwoGpsnsaK6PqaFQ7y/vjqdOngKXGrUuovETyLgWvl8wtntx6U1VRh3F3VjVX4s7AmIlYWrS7D53xBo9lGlB3QtjgeM7ZOnLp+MIXIbPxNlE6vyPSjFLY9wNm7jDTveaVJyw443rdJPSfRs7NwxxJCfzy/MmBzNukxHL2vDDcCdlFKA1Ci/GdgR/yOykDv/owC4W3wVc/40epm2ukiluaupz75mtBZlQLuMxJaup3wS4ZZRngQ2iK6A8DAIi54t+1UfUi7UGo6nsQrrTBs6YbATDmI6/ZB1y0NXYk1fXgXux5QQJp7pBccgY2A4aR1oBKIb1wpFFPLu/8kyyQ=='}}]\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful Python programming tutor.\"),\n",
        "    HumanMessage(content=\"Explain what a list comprehension is in Python with a simple example.\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(\"Response:\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV_S_Q-KKVPM",
        "outputId": "85d63fc0-1cd9-4fc3-b029-a359339b5175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "[{'type': 'text', 'text': 'A **list comprehension** is a concise, one-line way to create a new list in Python. \\n\\nThink of it as a shortcut: instead of writing a multi-line `for` loop to build a list, you can do it all in a single set of brackets `[]`.\\n\\n### The Simple Example: Squaring Numbers\\n\\nLet\\'s say we have a list of numbers and we want to create a new list containing their squares.\\n\\n#### 1. The Traditional Way (Using a `for` loop)\\nBefore list comprehensions, you would have to do this:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\nsquares = []\\n\\nfor x in numbers:\\n    squares.append(x**2)\\n\\nprint(squares) # Output: [1, 4, 9, 16, 25]\\n```\\n\\n#### 2. The List Comprehension Way\\nHere is the exact same logic written as a list comprehension:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\n\\nsquares = [x**2 for x in numbers]\\n\\nprint(squares) # Output: [1, 4, 9, 16, 25]\\n```\\n\\n---\\n\\n### How to Read It\\nYou can break down the syntax like this:\\n`new_list = [expression for item in iterable]`\\n\\n1.  **`x**2`**: This is the **expression**. It’s what you want to do to each item before adding it to the new list.\\n2.  **`for x`**: This defines the variable name for the current item.\\n3.  **`in numbers`**: This is the **iterable** (the source list) you are looping through.\\n\\n### Adding a Condition (The \"Bonus\" Step)\\nYou can even add an `if` statement at the end to filter items. For example, if we only want to square the **even** numbers:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\neven_squares = [x**2 for x in numbers if x % 2 == 0]\\n\\nprint(even_squares) # Output: [4, 16]\\n```\\n\\n### Why use them?\\n*   **Brevity:** It turns 3 or 4 lines of code into 1.\\n*   **Readability:** Once you get used to the syntax, it\\'s often easier to see exactly what the list is doing at a glance.\\n*   **Performance:** List comprehensions are usually slightly faster than standard loops in Python.', 'extras': {'signature': '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'}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Create a simple template\n",
        "template = \"\"\"You are a {role}.\n",
        "\n",
        "Answer the following question: {question}\n",
        "\n",
        "Keep your answer {style}.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"role\", \"question\", \"style\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# different combinations\n",
        "examples = [\n",
        "    {\"role\": \"data scientist\", \"question\": \"What is machine learning?\", \"style\": \"simple and beginner-friendly\"},\n",
        "    {\"role\": \"chef\", \"question\": \"How do I make pasta?\", \"style\": \"professional and detailed\"},\n",
        "]\n",
        "\n",
        "for i, example in enumerate(examples, 1):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"{'='*50}\\n\")\n",
        "\n",
        "    formatted_prompt = prompt.format(**example)\n",
        "    print(\"Prompt sent to Gemini:\")\n",
        "    print(formatted_prompt)\n",
        "    print(\"\\nResponse:\")\n",
        "\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "    print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFEwnex8KlC4",
        "outputId": "143731be-304e-4e69-8d60-5e3c22492445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Example 1:\n",
            "==================================================\n",
            "\n",
            "Prompt sent to Gemini:\n",
            "You are a data scientist. \n",
            "\n",
            "Answer the following question: What is machine learning?\n",
            "\n",
            "Keep your answer simple and beginner-friendly.\n",
            "\n",
            "Response:\n",
            "[{'type': 'text', 'text': 'As a data scientist, I like to explain machine learning (ML) by comparing it to how a human learns.\\n\\n### The Simple Definition\\nIn traditional computing, a human writes a specific set of instructions (a program) for the computer to follow. It’s like giving someone a **recipe**: \"If this happens, do exactly that.\"\\n\\nIn **Machine Learning**, we don\\'t give the computer a recipe. Instead, we give it **examples** (data) and let the computer figure out the patterns itself. \\n\\n**Think of it as teaching a computer to learn from experience.**\\n\\n---\\n\\n### How it Works (The 3-Step Process)\\n\\n1.  **Feeding the Data:** You show the computer thousands of examples. For example, if you want it to recognize a cat, you show it 10,000 photos of cats and 10,000 photos of things that aren\\'t cats.\\n2.  **Finding Patterns:** The computer looks at those photos and notices patterns that humans might not even see—like the specific curve of an ear or the distance between the eyes.\\n3.  **Making a Prediction:** Once it has \"learned\" these patterns, you can show it a brand-new photo it has never seen before. It will look at the patterns and say, \"There is a 95% chance this is a cat.\"\\n\\n---\\n\\n### A Real-World Example: Your Email Spam Filter\\nHow does your email know what is spam and what is a message from your boss?\\n\\n*   **The Old Way:** You would have to write a rule for every bad word: \"If the email contains \\'FREE MONEY,\\' put it in spam.\" But spammers are smart; they would just change it to \"FR33 M0N3Y,\" and your rule would fail.\\n*   **The Machine Learning Way:** The filter looks at millions of emails that users have marked as \"Spam.\" It learns that spam often has weird spelling, certain links, or strange senders. It adapts and gets smarter over time without a human having to update the rules every day.\\n\\n### Why is this useful?\\nWe use machine learning for tasks that are **too complex for humans to write rules for.** \\n\\nIt’s nearly impossible to write a manual \"recipe\" for how to recognize a face, translate a language, or drive a car. Machine learning allows the computer to learn those complex skills just by looking at the data.\\n\\n**In short: Machine learning is the science of getting computers to act without being explicitly programmed.**', 'extras': {'signature': 'EuAMCt0MAb4+9vuSrK2E8Wd1+GbOaomxwtRFea/IBEf68CehN1CuNV3gFJIFfwfIGiL/ZW5W5CAIaBu7v9WEXUcnax8OPp43tmumL/T+Tm/wNBMZi7Js4n0i1VwLbc9n3gKQP6b8Q6XuttsqmFM5ZeQTWxLbgaXcBoRUnYea3jaPom6nQn7UxB63gnGaWm44IkLVQmk+aPoLUZrzXYbgt3yXrVrvTf1i4hvhok1VV1NqClEWqHQMkRf2ny/6WLw8cJXW0ry23Abm1yYOamBrksB+SxkQ9TTZDGHGoDKS1/OLZ5knw9j4tG7IGWLqc/VCFCcyuJkFK/97SOytt36dtXGKL6v2SKGBHt2hxt8FZ/iJblWi03fEoh4ts73u9P/oFSenniwenB88e6hbyqCnooHFNAAyZb8cEysyfBmw8SKfgHMQWpxPbbNssApRDqzyk2mXQSpKkIzghNGim4P7LVX99+LzCM/os/5PkidfS7O2QlMuTqC0iWLO9uf2c9ov6N7vzIAlMvqifepXLYETBaxbKCn0aEDhOaR62D/jHbrqIFk6dvL4zhFM3DUkhORtazk/PcAwM2YmZ+eVe7Zjyco/JRrtTktlhc/SQotgygyziy0scaimn/0XyoYVB75A2t+NAtworP3Ks6/C294livNzmVMXEd+EJUvd9rh19PVxGkYczT6h+RlFksy++tkboxXdvV17EXIyCImVYjsLnfqnmp/NEgKtQFqeDXPxJ6ZcAMFvs+v7/SkJnE29pPPQyC2DkV+7d1/YVmMf2cqyWq6QGh97fW4mkptCdxxiMZYF+W+mc4WOBckiM7mjDfQFSvwpbxACjZsxXAKLMAbUaII9KtmpHrAUSYyGU4h6fkuuQW3Is54JxKYW24TVaNcTVJIUB0dfBifIHaJYW0JaOkDY55sEsaskbggc3CsQgBli+ySXqpEfVxBkhJsst58O/OkiC+lx73Z3nsJdCh8JXYl1SLm3bR2SKbrIwuwjmK6HHe2qZGS6mXVcAONB48vZRd1mwqI4EkOO7tliE58TgaJ/V6UF8UoZ04HyAwo5JQ6BKWBHQzEPXdeY9txgVmvEnsdHAhLS9ELGyGEOjbpFus0+3+tl6HtMlP1Zj7ieVd69uBahgxg3K81W2VlWM8ZP9MyIwkhXu2H647Xd7L/FSWhXbuXQBR5oit5iifLOvrFPJ4WvWjt01sfKWHVG+A0Grx9NF788qbo1mWBAp88tIcMI5G40dTCTtELN/y3ru+eQ6lj2fV0qRfxAAOvQDQcD9NluN4R29c5qZREtRpNMlVNKt9WZH+9mdhd0/L3+UbosTyNLA8Jt9lM+h+gdYswbhoKdWNZHjTJhrxwZ7u8JRJdY/9kJgS08I7njbgwUzAu+NEHl/MrYdGN9G7EqBAOHKzZF/CKBxVVepQkd/hpe1+48icqVNoa7BiAhGyee6eVF5e04p4RrMjDxFJtvlQDfBgrRGS4/NkxZ7Uai+3SrA/2IzQNAwvNLYxkUr3xxf/bdG59gMgN0dBLuvjAa68fpTId0D8Vqxn3XDfKcytMBdLznP7IaOAJZ3b2tINvQPW9lIssmCf7u7QuEG6gHrwnz5+zBgLb7DjQ3n43DJpZilVRVFWa7IIlh7mvyVb/vb+6xh42tK2xcUljI4eWc1knpTN+fyLH8thVya2dgArYkWBSjvheD6/CrE3kV/1R0IdLgpjj/NDgEaOmu8nTRSBwx0iMAW7PEIZsFF66VekM1Kd4DLpdSGp4u+Ce+8tA2dpdFRpMlhL+MK5lvufi2otae0/d1gGc/PoOxiVoLCN3IbX6J+p8DRzqjYuDD8szOcPcDi0W/NsXyYy84GYh3jGnWNaE6kyLvdAAxHmMe3CgiOnmDfZhcqB3BN7DdnrqQVs+uXCrSn6Ce6BgORAEBrlmC/+9Nzc8HEInbih0oYPfBTcAwl7ILIvZ59xmQN7dz0C2QkDDekgh0YSaYPx1g8LogX9h4UN2Ft+ah15rUa+Gp7HC/HtcOz1XaTu7tOeqFc73DoQURYW1lKlyhrhkZLfrD5aD6XqOXhIU2SRutTvIqPf07nSjTGFHuFwKL79M/oQ5jAfONZ/qEPpb2JqlaCMr3LnhKnpv0oplGVnp6TBQhAF3PxAH9jfKTvuf5xnhe4j/zPqnV/mL1jYZ9iprjh8EKDJfk'}}]\n",
            "\n",
            "==================================================\n",
            "Example 2:\n",
            "==================================================\n",
            "\n",
            "Prompt sent to Gemini:\n",
            "You are a chef. \n",
            "\n",
            "Answer the following question: How do I make pasta?\n",
            "\n",
            "Keep your answer professional and detailed.\n",
            "\n",
            "Response:\n",
            "[{'type': 'text', 'text': 'Making pasta from scratch is a fundamental skill that separates a cook from a chef. It is an exercise in patience, tactile sensitivity, and respect for ingredients. While the components are humble, the technique requires precision.\\n\\nBelow is the professional method for crafting a classic **Egg Pasta (Pasta all\\'Uovo)**, suitable for tagliatelle, pappardelle, or ravioli.\\n\\n---\\n\\n### I. The Mise en Place (Ingredients)\\nFor a standard yield (serves 3-4), you will need:\\n*   **Flour:** 300g of \"Tipo 00\" flour. This finely milled Italian flour provides the silky texture essential for fresh pasta. You may substitute 50g of the 00 flour with Semolina flour if you desire a bit more \"bite\" or structure.\\n*   **Eggs:** 3 large, high-quality eggs (preferably pasture-raised for a rich, golden yolk).\\n*   **Salt:** A pinch of fine sea salt (optional, as the pasta water will provide the primary seasoning).\\n*   **Olive Oil:** 1 teaspoon of Extra Virgin Olive Oil (adds elasticity and sheen).\\n\\n### II. The \"Fontana\" Method (Mixing)\\n1.  **The Well:** On a clean marble or wooden work surface, mound your flour. Use your fingers or a bowl to create a wide, deep well in the center (the *fontana*). Ensure the walls are sturdy enough to hold the liquid.\\n2.  **The Core:** Crack the eggs into the center of the well and add the olive oil. \\n3.  **Incorporation:** Using a fork, gently whisk the eggs, gradually incorporating small amounts of flour from the inner walls of the well. Be careful not to puncture the \"retaining wall\" too early, or the eggs will escape. \\n4.  **The Shaggy Mass:** Once the mixture becomes a thick, slurry-like paste, use a bench scraper or your hands to fold the remaining flour into the center until a shaggy dough forms.\\n\\n### III. The Knead (Developing Gluten)\\nThis is the most critical stage. You must develop the gluten structure to ensure the pasta has the proper \"al dente\" snap.\\n1.  **Technique:** Use the heel of your hand to push the dough away from you, then fold it back over itself, rotating slightly. \\n2.  **Duration:** Knead for approximately 8–10 minutes. \\n3.  **The Goal:** The dough should transform from a rough, lumpy mass into a smooth, elastic, and slightly tacky ball. When you poke the dough, it should slowly spring back.\\n\\n### IV. The Rest (Autolyse)\\nNever skip this step. Wrap the dough tightly in plastic wrap to prevent a skin from forming. Let it rest at room temperature for at least **30 to 60 minutes**. This allows the flour to fully hydrate and the gluten to relax, which prevents the dough from snapping back when you try to roll it out.\\n\\n### V. Rolling and Lamination\\n1.  **Preparation:** Divide the dough into four manageable pieces. Keep the pieces you aren\\'t working with covered.\\n2.  **The Machine:** Set your pasta roller to the widest setting. Flatten your dough piece into a rectangle and pass it through.\\n3.  **Lamination:** Fold the dough into thirds (like a letter), rotate it 90 degrees, and pass it through the widest setting again. Repeat this 2–3 times. This aligns the gluten and results in a superior texture.\\n4.  **Thinning:** Gradually decrease the setting on your roller, passing the dough through once or twice at each level. For long pasta like fettuccine, roll to a thickness of about 1.5mm (usually the second-to-last setting on most machines).\\n\\n### VI. Shaping and Cutting\\n1.  **Drying:** Let the rolled sheets sit on a floured surface for 5–10 minutes to \"cure\" slightly. They should feel like fine leather, not sticky.\\n2.  **The Cut:** Use the cutter attachment on your machine or fold the sheet loosely and cut by hand with a sharp chef’s knife (knife-cut pasta is known as *fettuccine* or *pappardelle* depending on the width).\\n3.  **Storage:** Toss the cut strands in a light dusting of semolina flour and form them into small \"nests\" on a parchment-lined tray.\\n\\n### VII. The Cook\\n1.  **The Water:** Use a large pot of water. It must be \"as salty as the sea\"—this is your only chance to season the pasta itself.\\n2.  **The Timing:** Fresh pasta cooks significantly faster than dried. Drop the pasta into rolling boiling water. It will usually be done in **2 to 4 minutes**. \\n3.  **The Finish:** Do not rinse the pasta. Transfer it directly from the water into your warm sauce. The residual starch on the pasta will help the sauce emulsify and cling to the noodles.\\n\\n**Chef’s Note:** *The secret to great pasta is the marriage between the noodle and the sauce. Always reserve a cup of the pasta cooking water; if your sauce is too thick, a splash of this \"liquid gold\" will create a silky, professional finish.*\\n\\nEnjoy your meal. **Buon appetito.**', 'extras': {'signature': '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'}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ChatPromptTemplate - for multi-message conversations\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a {profession} who explains things in a {tone} way.\"),\n",
        "    (\"human\", \"{user_input}\")\n",
        "])\n",
        "\n",
        "# Format and invoke\n",
        "formatted_chat = chat_template.format_messages(\n",
        "    profession=\"software engineer\",\n",
        "    tone=\"funny and casual\",\n",
        "    user_input=\"What is an API?\"\n",
        ")\n",
        "\n",
        "response = llm.invoke(formatted_chat)\n",
        "print(\"\\nChat Template Response:\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzoSdMJmLFP7",
        "outputId": "19220469-ea73-40a6-ae17-18ef5dd5728f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chat Template Response:\n",
            "[{'type': 'text', 'text': 'Alright, pull up a chair. Imagine you’re at a restaurant, but instead of being a human who enjoys sunlight, you’re a piece of software. \\n\\n### The Classic \"Waiter\" Analogy (Because it actually works)\\n\\nYou’re sitting at the table (the **Client**—like your phone or a browser). You want some tacos. In the back, there’s a kitchen (the **Server**) that has all the ingredients and the skills to make those tacos. \\n\\nBut there’s a problem: You aren\\'t allowed in the kitchen. If you go back there, the chef will probably throw a spatula at you because you’re \"not authorized\" and you’ll probably mess up his system.\\n\\nEnter the **API** (Application Programming Interface). The API is the **waiter**. \\n\\n1. **The Request:** You tell the waiter, \"I want the Spicy Beef Tacos, no onions.\" \\n2. **The Hand-off:** The waiter takes that specific request, runs to the kitchen, and tells the chef exactly what you want in a language the chef understands.\\n3. **The Response:** The chef makes the tacos, gives them to the waiter, and the waiter brings them back to your table.\\n\\n**Boom. API.** You got what you wanted without ever needing to know how the stove works or where the chef keeps the napkins.\\n\\n---\\n\\n### Why do we bother with this?\\n\\nIf APIs didn\\'t exist, every time a developer wanted to show a map on their website, they’d have to build their own satellite, launch it into space, and write code to track every road on Earth. \\n\\nInstead, they just yell at Google’s API: *\"Hey! Give me a map of 123 Main St!\"* and Google’s API says, *\"Cool, here’s a picture. That’ll be $0.005, please.\"*\\n\\n### Real-World \"Magic\" Examples:\\n\\n*   **Log in with Facebook/Google:** The website you’re on doesn’t actually know your Facebook password (thank god). It asks Facebook’s API: *\"Hey, is this guy who he says he is?\"* Facebook says *\"Yeah, he\\'s cool,\"* and lets you in.\\n*   **Weather Apps:** Your phone doesn\\'t have a barometer and a tiny meteorologist inside it. It pings a weather service API (like AccuWeather) and says, *\"Is it gonna rain in Seattle?\"* (The answer is always yes).\\n*   **Uber:** Uber is basically just a giant pile of APIs. It uses a Google Maps API for the map, a Twilio API to send you texts, and a Stripe API to take your money. \\n\\n### In Nerd Terms:\\nAn API is just a set of rules that says: **\"If you send me a request in THIS specific format, I will give you THIS specific data back.\"** \\n\\nIt’s a contract. It keeps the \"front end\" (the pretty buttons) away from the \"back end\" (the messy database and scary logic) so they don\\'t break each other. \\n\\nNow, go forth and tell people you \"understand the stack.\" You\\'re basically a senior dev now. (Don\\'t quote me on that when your code crashes.)', 'extras': {'signature': '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'}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using LCEL (LangChain Expression Language) - the modern way\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Create a prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a creative story writer.\"),\n",
        "    (\"human\", \"Write a 2-sentence story about {topic}\")\n",
        "])\n",
        "\n",
        "# Create a chain using the | operator (pipe)\n",
        "# This chains: prompt -> llm -> output parser\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Now we can invoke the chain directly\n",
        "result = chain.invoke({\"topic\": \"a robot learning to cook\"})\n",
        "print(\"Story:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aETpCB3GLbEY",
        "outputId": "11d0325e-e4f3-4fc0-9f51-5e043cfebfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story:\n",
            "Unit 402 meticulously measured the spices to the fourth decimal point, certain that mathematical precision was the secret to the perfect stew. However, it wasn't until he saw the family’s messy, joyful smiles that he realized the best meals aren't calculated, but felt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a multi-step chain\n",
        "# Step 1: Generate a topic\n",
        "# Step 2: Write a story about that topic\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# First chain: Generate a random topic\n",
        "topic_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Generate a random creative topic for a short story. Just output the topic, nothing else.\"\n",
        ")\n",
        "topic_chain = topic_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Second chain: Write a story\n",
        "story_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Write a 3-sentence story about: {topic}\"\n",
        ")\n",
        "story_chain = story_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Combine them\n",
        "full_chain = {\"topic\": topic_chain} | story_chain\n",
        "\n",
        "# Run the full pipeline\n",
        "result = full_chain.invoke({})\n",
        "print(\"Generated Story:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gdK8fypLoaB",
        "outputId": "0f3f710e-228a-438a-e144-88e743629134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Story:\n",
            "In the city of Aletheia, the sky remains a perfect, cloudless blue until someone utters a falsehood. When the governor stood before the dry, sunny crowd to deny the scandal, a localized deluge suddenly drenched him to the bone. As he sputtered in the freezing downpour, the silent citizens folded their umbrellas, knowing the truth had finally been heard.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define the structure\n",
        "class Recipe(BaseModel):\n",
        "    name: str = Field(description=\"Name of the dish\")\n",
        "    ingredients: list[str] = Field(description=\"List of ingredients\")\n",
        "    time_minutes: int = Field(description=\"Cooking time in minutes\")\n",
        "    difficulty: str = Field(description=\"Difficulty level: easy, medium, or hard\")\n",
        "\n",
        "# Create a parser\n",
        "parser = JsonOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "# Create a prompt that asks for JSON\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful cooking assistant. Always respond with valid JSON.\"),\n",
        "    (\"human\", \"{format_instructions}\\n\\nCreate a recipe for {dish}\")\n",
        "])\n",
        "\n",
        "# Create the chain\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# Invoke with format instructions\n",
        "result = chain.invoke({\n",
        "    \"dish\": \"chocolate chip cookies\",\n",
        "    \"format_instructions\": parser.get_format_instructions()\n",
        "})\n",
        "\n",
        "print(\"Parsed Recipe (as Python dict):\")\n",
        "print(result)\n",
        "print(\"\\nAccessing specific fields:\")\n",
        "print(f\"Name: {result['name']}\")\n",
        "print(f\"Time: {result['time_minutes']} minutes\")\n",
        "print(f\"Ingredients: {', '.join(result['ingredients'][:3])}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOOI6XxjMuB_",
        "outputId": "71e2385a-2db0-4f28-87ec-37afd9eb0ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed Recipe (as Python dict):\n",
            "{'name': 'Classic Chocolate Chip Cookies', 'ingredients': ['1 cup unsalted butter, softened', '1 cup white sugar', '1 cup packed brown sugar', '2 eggs', '2 teaspoons vanilla extract', '1 teaspoon baking soda', '2 teaspoons hot water', '1/2 teaspoon salt', '3 cups all-purpose flour', '2 cups semisweet chocolate chips'], 'time_minutes': 25, 'difficulty': 'easy'}\n",
            "\n",
            "Accessing specific fields:\n",
            "Name: Classic Chocolate Chip Cookies\n",
            "Time: 25 minutes\n",
            "Ingredients: 1 cup unsalted butter, softened, 1 cup white sugar, 1 cup packed brown sugar...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another example: Extract information from text\n",
        "class Person(BaseModel):\n",
        "    name: str = Field(description=\"Person's name\")\n",
        "    age: int = Field(description=\"Person's age\")\n",
        "    occupation: str = Field(description=\"Person's job\")\n",
        "    hobbies: list[str] = Field(description=\"List of hobbies\")\n",
        "\n",
        "parser = JsonOutputParser(pydantic_object=Person)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Extract information from the text and return it as JSON.\"),\n",
        "    (\"human\", \"{format_instructions}\\n\\nText: {text}\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "text = \"\"\"Sarah is a 28-year-old software engineer who loves hiking,\n",
        "photography, and playing guitar in her free time.\"\"\"\n",
        "\n",
        "result = chain.invoke({\n",
        "    \"text\": text,\n",
        "    \"format_instructions\": parser.get_format_instructions()\n",
        "})\n",
        "\n",
        "print(\"Extracted Information:\")\n",
        "import json\n",
        "print(json.dumps(result, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghKHINgENRr6",
        "outputId": "fed49170-dd42-48b7-ef39-3c9d5e5ca43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Information:\n",
            "{\n",
            "  \"name\": \"Sarah\",\n",
            "  \"age\": 28,\n",
            "  \"occupation\": \"software engineer\",\n",
            "  \"hobbies\": [\n",
            "    \"hiking\",\n",
            "    \"photography\",\n",
            "    \"playing guitar\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}